{
	"version": "https://jsonfeed.org/version/1.1",
	"title": "Personal Data and AI Department",
	"language": "en",
	"home_page_url": "https://bellowswang.github.io/",
	"feed_url": "https://bellowswang.github.io/feed.json",
	"description": "I build my own data and AI department, and help people build their own data and AI department of themselves, by themselves, and for themselves",
	"author": {
		"name": "Yihong Wang",
		"url": "https://bellowswang.github.io/about-me/"
	},
	"items": [
		{
			"id": "https://bellowswang.github.io/blog/baby-agent/",
			"url": "https://bellowswang.github.io/blog/baby-agent/",
			"title": "Everyone (including new parents at 3am) should have their own AI agent.",
			"content_html": "<p>Two things happened to me at the end of 2025. I became a proud father. And I switched to a new team at work and started working on building AI agents. Naturally, I wanted to combine both into one side project, not only making my life easier as a father (hopefully), but also helping me learn more about building AI agents.</p>\n<p>When you have a newborn, your life becomes a series of data points: how many milliliters of milk, which side for breastfeeding, how many wet diapers, how many minutes of sleep, what time was the last feeding. The kraamzorg asks you these questions at every visit. Your wife asks you at every handoff. You ask yourself at 3am when you can't remember if the last bottle was 30 minutes ago or 3 hours ago.</p>\n<p>Of course, there are apps for this. I tried Huckleberry, which is one of the most popular baby tracking apps. But the core features are basic. You just log events (feedings, diapers, sleep) and see visualizations. Tap a category, fill in a form, submit. It works, but it felt like exactly the kind of thing an AI agent could replace. And with an LLM in the loop, the logging interface could be much more casual - no rigid forms, just natural language. You could text &quot;120ml at 2pm&quot; in a family group chat and be done with it.</p>\n<p>So I decided to build an AI agent that my whole family could use, which is a Telegram bot where anyone could send a natural language message and have it logged into a PostgreSQL database automatically (remember I set up a database for my DNA Department in a previous <a href=\"https://bellowswang.github.io/blog/database/\">post</a>?). No forms, no dropdowns, no app to learn. Just text what happened, in Chinese or English, and the agent handles the rest.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/al7ExAEtAL-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/al7ExAEtAL-600.webp 600w\"><img alt=\"My AI agent for baby tracking.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/al7ExAEtAL-600.png\" width=\"600\" height=\"1298\"></picture></p>\n<h3 id=\"the-project-a-telegram-bot-baby-tracker\" tabindex=\"-1\">The project: a Telegram bot baby tracker <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/baby-agent/\">#</a></h3>\n<p>The idea was simple. A family Telegram group where anyone (my wife, my parents, my in-laws) could log baby activities by just sending a message. The agent would:</p>\n<ul>\n<li>Parse natural language input in Chinese or English</li>\n<li>Log the data into my self-hosted PostgreSQL tables (feedings, diapers, sleep, supplements, growth, temperature)</li>\n<li>Respond with a confirmation and a 24-hour summary</li>\n<li>Answer ad-hoc questions like &quot;how much milk did the baby drink today?&quot; or &quot;show me a chart of sleep patterns this week&quot;</li>\n</ul>\n<p>The database schema covers eight activity types: bottle feedings, breastfeeding, diapers, sleep, pumping, supplements, growth measurements, and temperature readings. All tables live in a schema with timestamps and a field tracking who sent the message.</p>\n<h3 id=\"framework-choice-claude-agent-sdk\" tabindex=\"-1\">Framework choice: Claude Agent SDK <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/baby-agent/\">#</a></h3>\n<p>I'm a Claude Max subscriber and Claude Code power user, so the Claude Agent SDK was the natural choice for building this agent. There was one concern: at the time, the SDK wasn't fully open-sourced, which made it harder to understand the internals.</p>\n<p>But I found <a href=\"https://github.com/shareAI-lab/learn-claude-code\">learn-claude-code</a>, a community project that reverse-engineered the core concepts behind Claude Code's agent architecture. Reading through that codebase turned out to be one of the most important things I did for this project, not only for the baby tracker specifically, but also for understanding what makes something truly agentic.</p>\n<h3 id=\"version-1-the-non-agentic-agent\" tabindex=\"-1\">Version 1: the non-agentic agent <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/baby-agent/\">#</a></h3>\n<p>Here's the ironic thing. I used Claude Code, arguably the most powerful agentic coding tool available, to build my first version of the baby tracker. And it produced the most non-agentic code ever.</p>\n<p>The first version had nine separate Python tool files, each one a hardcoded function with explicit validation logic, explicit database operations, and explicit response formatting:</p>\n<ul>\n<li><code class=\"language-\">bottle_feeding.py</code></li>\n<li><code class=\"language-\">breastfeeding.py</code></li>\n<li><code class=\"language-\">diaper.py</code></li>\n<li><code class=\"language-\">sleep.py</code></li>\n<li><code class=\"language-\">pumping.py</code></li>\n<li><code class=\"language-\">growth.py</code></li>\n<li><code class=\"language-\">supplement.py</code></li>\n<li><code class=\"language-\">temperature.py</code></li>\n<li><code class=\"language-\">summary.py</code> + <code class=\"language-\">utils.py</code></li>\n</ul>\n<p>Each tool had a rigid function signature: <code class=\"language-\">log_bottle_feeding(volume_ml=100, type=&quot;formula&quot;)</code>. Each tool manually validated inputs, manually converted timezones, manually formatted responses, and manually calculated 24-hour summaries. The agent's job was reduced to: parse the user's message, figure out which specific pre-defined function to call, fill in the parameters, return the result.</p>\n<p>It worked. But it was not there yet. Want to add a new tracking category? Write another file. Want to change how summaries are calculated? Edit every single tool file. Want the agent to generate a chart? Sorry, there's no tool for that.</p>\n<h3 id=\"the-revelation-what-makes-something-truly-agentic\" tabindex=\"-1\">The revelation: what makes something truly agentic? <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/baby-agent/\">#</a></h3>\n<p>Then I read through the <a href=\"https://github.com/shareAI-lab/learn-claude-code\">learn-claude-code</a> codebase, and something clicked.</p>\n<p>Claude Code doesn't have a <code class=\"language-\">fix_bug()</code> tool or a <code class=\"language-\">refactor_function()</code> tool or a <code class=\"language-\">write_test()</code> tool. It has primitive, general-purpose tools:</p>\n<ul>\n<li><strong>Read</strong> — read a file</li>\n<li><strong>Write</strong> — write a file</li>\n<li><strong>Glob</strong> — find files by pattern</li>\n<li><strong>Grep</strong> — search file contents</li>\n</ul>\n<p>That's it. You give it capabilities, not purposes. The agent figures out what steps to take, what code to write, what commands to run, all in a while loop. You don't define a workflow. Instead you define a toolbox. The magic is in the <a href=\"https://arxiv.org/abs/2210.03629\">ReAct</a>/<a href=\"https://arxiv.org/abs/2402.01030\">CodeAct</a>-style agent while loop: the model observes the environment, reasons about what to do, takes an action, observes the result, and repeats, until the purpose is achieved.</p>\n<p>This was the fundamental mistake in my Version 1. I had defined purposes (log a bottle feeding, query diapers, calculate summaries) instead of capabilities (read files, run code, query a database). I had built an explicit workflow, not an agent.</p>\n<h3 id=\"version-2-the-truly-agentic-approach\" tabindex=\"-1\">Version 2: the truly agentic approach <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/baby-agent/\">#</a></h3>\n<p>Armed with this insight, I rewrote the entire thing. Here's the core of the new agent configuration:</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\">builtin_tools <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"Bash\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Read\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Glob\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Grep\"</span><span class=\"token punctuation\">]</span></code></pre>\n<p>Four tools. That's all. The agent gets:</p>\n<ol>\n<li>A system prompt explaining what it is (a baby tracker for family use)</li>\n<li>A <code class=\"language-\">.claude/CLAUDE.md</code> file documenting the database schema and connection code</li>\n<li>Four built-in tools to interact with the environment</li>\n</ol>\n<p>When a user sends &quot;120ml formula&quot;, the agent doesn't call a specific <code class=\"language-\">log_bottle_feeding()</code> function. Instead, it:</p>\n<ol>\n<li>Reads <code class=\"language-\">.claude/CLAUDE.md</code> to understand the database schema</li>\n<li>Writes Python code to insert a row into my <code class=\"language-\">bottle_feedings</code> table</li>\n<li>Runs the code via Bash</li>\n<li>Queries the database for 24-hour totals</li>\n<li>Formats a response</li>\n</ol>\n<p>When a user asks &quot;show me a chart of feeding patterns this week&quot;, the agent doesn't return an error saying &quot;no chart tool available.&quot; Instead, it:</p>\n<ol>\n<li>Writes Python code using matplotlib to query the database and generate a chart</li>\n<li>Saves the chart as a PNG</li>\n<li>Returns the image</li>\n</ol>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/cqtPgd7IMt-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/cqtPgd7IMt-600.webp 600w\"><img alt=\"My AI agent shows me the sleeping chart.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/cqtPgd7IMt-600.png\" width=\"600\" height=\"1298\"></picture></p>\n<h3 id=\"the-essence-of-agentic-ability\" tabindex=\"-1\">The essence of agentic ability <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/baby-agent/\">#</a></h3>\n<p>The experience crystallized a simple framework for thinking about AI agents:</p>\n<p><strong>Workflow approach</strong> (Version 1): You define the steps. The LLM fills in the blanks within each step. You are the architect, the model is the laborer.</p>\n<p><strong>Agent approach</strong> (Version 2): You define the capabilities. The LLM decides the steps. You provide the toolbox, the model is the architect.</p>\n<p>The irony still feels funny to me. The most agentic coding tool in the world, Claude Code, initially produced the most non-agentic code when I asked it to build an agent. I think that was on me though. It's because in my prompt, I asked it to &quot;build a baby tracker with tools for each activity type.&quot; I described a workflow. It built a workflow. The tool faithfully implemented my non-agentic design.</p>\n<p>The lesson: give the agent narrow, purpose-built tools, and you get a narrow, purpose-built system. Give it general-purpose capabilities and good documentation, and you get something that can handle anything you throw at it, including things you never anticipated.</p>\n<h3 id=\"is-software-dead\" tabindex=\"-1\">Is software dead? <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/baby-agent/\">#</a></h3>\n<p>Building this agent made me think about the &quot;software is dead&quot; narrative that's been going around. The idea is that AI agents will replace traditional SaaS products. When Claude launched Cowork and made plugins available for industries like legal, the stock market dipped because people started doubting the future of SaaS. And honestly, my experience building this baby tracker is a data point in that direction. Huckleberry is a well-designed app with a team behind it, and I replaced its core functionality with a weekend project.</p>\n<p>I've seen this pattern in other areas of my life too. Last year when I moved to a new house, I chose Apple HomeKit over Home Assistant because I thought maintaining Home Assistant would be too time-consuming. If I were making that choice today, it would be a no-brainer. Home Assistant all the way. With tools like Claude Code, the &quot;maintenance burden&quot; of self-hosted, open-source software has dropped dramatically. The trade-off has shifted.</p>\n<p>But I don't think the story is that simple. There's one thing Huckleberry has that my agent doesn't: a data flywheel. Huckleberry has data from thousands of babies — their sleep patterns, their feeding schedules, their growth curves. They can train algorithms to predict the optimal nap time for your specific baby based on patterns from all the other babies in their dataset. My agent only has data from one baby. I can use an LLM as a common-sense sanity check (&quot;does this sleep schedule seem normal for a 2-month-old?&quot;), but that's not the same as a quantitative prediction model trained on real data from thousands of infants in this specific domain.</p>\n<p>So maybe software isn't dead, but the moat has moved. The moat is no longer the UI, the forms, the basic CRUD operations. Those are replaceable by agents. The moat is the data. The flywheel that no individual user can replicate on their own.</p>\n<h3 id=\"is-the-dashboard-dead\" tabindex=\"-1\">Is the dashboard dead? <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/baby-agent/\">#</a></h3>\n<p>I wrote about setting up my own <a href=\"https://bellowswang.github.io/blog/dashboard/metabase/\">Metabase dashboards</a> as a core piece of my DNA department. Now that I have an agent that can generate any chart on demand via Telegram, do I still need them?</p>\n<p>This is actually a classic debate in data teams: curated dashboards vs. self-service ad-hoc analysis. After living with both, I think they serve fundamentally different modes.</p>\n<p><strong>Dashboards are for monitoring.</strong> You open Metabase and immediately see 5-10 metrics at a glance: total milk today, diaper count, sleep hours, feeding trend this week. Your eye catches the anomaly without asking a question. It's the single source of truth for your KPIs, rendered the same way every time, instantly, for free.</p>\n<p><strong>Chat is for investigation.</strong> &quot;What's the correlation between sleep duration and feeding volume this week?&quot; or &quot;Compare this week's feeding pattern to last week.&quot; These are questions you can't pre-build a dashboard for. The agent writes custom code, generates a one-off chart, and you ask follow-up questions. That flexibility is something no dashboard can match.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/Py-OemgxMr-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/Py-OemgxMr-600.webp 600w\"><img alt=\"Chart made by my AI agent.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/Py-OemgxMr-600.jpeg\" width=\"600\" height=\"341\"></picture></p>\n<p>The lines do blur though. You could persist the logic for generating a specific chart as an agent skill, so it produces the same stats the same way every time, which is functionally similar to a dashboard view. But each run still costs API tokens and has latency (the agent thinks, writes code, runs it), while Metabase loads instantly. For something you check five times a day, that difference matters.</p>\n<p>Where dashboards win: glanceability, zero latency, shared views the whole family can bookmark. Where chat wins: unlimited flexibility, follow-up questions, no maintenance when the schema changes. But both are <strong>pull</strong> interfaces, so you need to go to them. There's a third mode that neither does well: <strong>push.</strong> The agent comes to you. &quot;The baby slept 30% less than usual today.&quot; &quot;Feeding volume is trending down this week.&quot; A Telegram-based agent is naturally suited for this. It's already in your chat. As a next step, I'll explore how to make the agent more proactive and share with you in future.</p>\n<p>My current take: I'll probably shift most of my ad-hoc analysis to the chat interface and keep Metabase for the persistent, at-a-glance monitoring dashboard. The agent is better for exploring; the dashboard is better for watching.</p>\n<h3 id=\"my-dna-department-grows\" tabindex=\"-1\">My DNA department grows <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/baby-agent/\">#</a></h3>\n<p>My personal DNA department now has its first AI employee. It works the night shift. It speaks Chinese and English. It's a generalist, being so agentic that it doesn't need a dedicated script for learning a new tool — you just update the documentation and it figures out the rest by itself. What's the next agent the department might have? Stay tuned.</p>\n",
			"date_published": "2026-02-08T00:00:00Z"
		}
		,
		{
			"id": "https://bellowswang.github.io/blog/running/",
			"url": "https://bellowswang.github.io/blog/running/",
			"title": "How I logged and analyzed my running data to track progress in 2024",
			"content_html": "<p>Recently, my personal &quot;Fitness Department&quot; reached out to my &quot;Data and AI Department&quot; with a request: analyze my running performance for the year of 2024. While this &quot;department&quot;-level communication is imaginary, the challenge was very real, and I decided to prioritize this project at the start of 2025.</p>\n<p>Reflecting on it, taking up running was undoubtedly one of the highlights of my 2024. My initial motivation was to maximize my VO2 max, and while my Apple Watch provides an estimate of this metric, its calculation process remains a black box to me. Through some research, I learned that VO2 max generally improves when you can either run at a lower heart rate for the same pace or sustain a higher pace at the same heart rate over a given distance. Apple's Fitness app does offer pace and heart rate data per kilometer for each run, but I wanted a more holistic view. To analyze trends across three dimensions: pace, heart rate and mileage. I needed a far more flexible approach than what the app could provide.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/Z70ramYOYo-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/Z70ramYOYo-600.webp 600w\"><img alt=\"Running at Central Park in the summer of 2024.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/Z70ramYOYo-600.jpeg\" width=\"600\" height=\"800\"></picture></p>\n<h3 id=\"architecture-of-the-project\" tabindex=\"-1\">Architecture of the project <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/running/\">#</a></h3>\n<p>If you’ve read my previous blog posts on why and how everyone should set up their own <a href=\"https://bellowswang.github.io/blog/database/\">databases</a> and <a href=\"https://bellowswang.github.io/blog/dashboard/metabase/\">dashboards</a>, you’ll find the architecture of this project just as straightforward. It revolves around two components: storing my running data in my own database and analyzing it using my own dashboards.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/CNX3TOyLJL-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/CNX3TOyLJL-600.webp 600w\"><img alt=\"Architecture of the project.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/CNX3TOyLJL-600.png\" width=\"600\" height=\"521\"></picture></p>\n<h3 id=\"logging-the-data\" tabindex=\"-1\">Logging the data <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/running/\">#</a></h3>\n<p>While I’m still working on a fully automated pipeline to transfer data from Apple’s Fitness app to my database, I’ve been manually logging my running data in a Google Sheet for now. This sheet includes four columns: date, pace, heart rate, and distance (in km). A semi-automated pipeline triggers a workflow scheduler to load the data from Google Sheets into my database.</p>\n<p>This setup not only allows me to analyze my data more flexibly but also ensures permanent storage of my data on my own machine, which has two main advantages:</p>\n<ul>\n<li>Data longevity: While it might seem unlikely, apps from tech companies have been shut down in the past, leaving users at risk of losing their data. If Apple ever decides to discontinue the Fitness app, my data will still be safe.</li>\n<li>Future possibilities: Storing my running data now opens the door to combining it with other datasets in the future. This will allow me to explore correlations and even conduct causal analyses across various aspects of my personal data.</li>\n</ul>\n<h3 id=\"analyzing-the-data\" tabindex=\"-1\">Analyzing the data <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/running/\">#</a></h3>\n<p>Here’s the visualization I envisioned before starting this project: a scatterplot of my heart rate versus pace for a specific kilometer, with points colored by the month. The y-axis represents heart rate (lower is better), and the x-axis represents pace in minutes per kilometer (also lower is better). My ultimate goal is to shift the trend line between heart rate and pace toward the bottom-left corner of the chart. This makes it easy to track my progress over time.</p>\n<img src=\"https://bellowswang.github.io/img/fOwRrWS1-Y-600.gif\" alt=\"My running data in 2024.\" width=\"600\" height=\"32985\" style=\"max-width: 100%; height: auto;\" loading=\"lazy\" decoding=\"async\">\n<p>The results? I’ve been improving steadily, with the most significant progress occurring in September. For a certain kilometer, I could sustain a much higher pace at the same heart rate or a much lower heart rate at the same pace. I noticed another potential leap in November, but due to moving houses and my parents' visit, I couldn’t maintain my running routine. By the time I resumed in December, my performance had slightly regressed.</p>\n",
			"date_published": "2025-01-19T00:00:00Z"
		}
		,
		{
			"id": "https://bellowswang.github.io/blog/dashboard/metabase/",
			"url": "https://bellowswang.github.io/blog/dashboard/metabase/",
			"title": "Everyone (including Mr. &amp; Mrs. Smith) should have their own data dashboards.",
			"content_html": "<p>Hihi, at our personal DNA (Data and AI) department, we've built our <a href=\"https://bellowswang.github.io/blog/database/\">database</a> and started ingesting our personal data to the database using some Python scripts. Moreover, we can use database clients like DBeaver to see the data, but in a not so friendly way, just in terms of tables. How can we further visualise the data? Simple data visualisation can just unlock so many insights. A self-hosted data dashboard is a must-to-have component for our personal DNA department.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/gaHS91IMk2-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/gaHS91IMk2-600.webp 600w\"><img alt=\"Create a random table.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/gaHS91IMk2-600.jpeg\" width=\"600\" height=\"600\"></picture></p>\n<h3 id=\"what-is-a-data-dashboard-chatgpt-definition\" tabindex=\"-1\">What is a data dashboard? (ChatGPT definition) <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/dashboard/metabase/\">#</a></h3>\n<blockquote>\n<p>'A data dashboard is a visual representation of key performance indicators (KPIs), metrics, and other important data points, typically presented in a graphical format. It provides a consolidated view of an organization's data, allowing users to monitor trends, analyze performance, and make informed decisions.'</p>\n</blockquote>\n<p>Apparently, ChatGPT assumes the dashboard is typically used for an organization, but I mean we can also do exactly the same things of ourselves, by ourselves and for ourselves. After all, an organization could also be a one-person organization. People have their own KPIs, even though sometimes we're not aware of them or haven't just quantified them. Just think about our new year resolutions. If they could be quantified, they could potentially be tracked and analyzed in a dashboard.</p>\n<h3 id=\"why-a-self-hosted-data-dashboard-vs-creating-charts-in-google-sheet\" tabindex=\"-1\">Why a self-hosted data dashboard (vs. creating charts in Google Sheet) <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/dashboard/metabase/\">#</a></h3>\n<p>The name 'Google Sheet' implies that it is mainly about sheets. The chart creation is not powerful at all based on my limited experience with it. More important, we've adopted the philosophy of maintaining our personal single source of truth in a database, instead of all over the place in google sheets. A self-hosted data dashboard that can be connected to database is a natural choice.</p>\n<h3 id=\"types-of-dashboards\" tabindex=\"-1\">Types of dashboards <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/dashboard/metabase/\">#</a></h3>\n<p>There are several types of dashboards, with two of the most common being pre-built dashboards with SQL interface and customizable dashboards with code-based interfaces. Tableau, Superset, Metabase, etc. fall into the former, while Python libraries like Dash and Streamlit fall into the latter. Dashboards like metabase with SQL interface provide a user-friendly interface where users can connect to databases and build dashboards by writing SQL queries and using a drag-and-drop interface. Dashboards like Streamlit with code-based interface require scripting to build visualisations, but they do offer greater flexibility and customization options compared to pre-built solutions.</p>\n<p>There are other specific dashboard types, for example, dashboards that are good at plotting geospatial information on the maps (e.g., Kepler), dashboards that are more suitable for real-time streaming data (e.g., Grafana) and dashboards that are dedicatedly for graph-structure data (e.g., Neo4j). We leave them out of the scope for now. Later when specific needs come, we can deep dive into those tools as well. The principal is more or less the same though. We want a place where we can plug in our databases and get the data visualised.</p>\n<p>While I use Streamlit from time to time (e.g., <a href=\"https://github.com/bellowswang/shabbyetf\">a streamlit-based dashboard</a> tracking the &quot;ETF&quot; co-owned by me and my several friends), my go-to dashboard for my personal DNA projects is Metabase. It's extremely simple to use and meets all my needs to track and analyse my own data.</p>\n<h3 id=\"how-to-host-a-dashboard-by-yourself\" tabindex=\"-1\">How to host a dashboard by yourself? <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/dashboard/metabase/\">#</a></h3>\n<p>Hosting a dashboard by yourself is way easier than you could imagine, just like hosting a database by yourself. To host Metabase on our local laptop, again a docker compose file (see <a href=\"https://www.metabase.com/docs/latest/installation-and-operation/running-metabase-on-docker\">the official doc</a> about how to write a docker compose file for Metabase) and a simple <code class=\"language-\">docker-compose up</code> command would quickly set up one. Note that you would need to set up your database and your Metabase in the same docker network, so that they can talk to each other. In our case, it's important that Metabase can seamlessly connect to the self-hosted database.</p>\n<h3 id=\"how-to-create-a-dashboard\" tabindex=\"-1\">How to create a dashboard? <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/dashboard/metabase/\">#</a></h3>\n<p>Let's assume we currently host our dashboard at <code class=\"language-\">localhost:3000</code>. Just go to <code class=\"language-\">localhost:3000</code> in your web browser and you will see the ready-to-use Metabase interface. As an admin, you're by default both a dashboard developer and a dashboard user. Since the organisation only includes yourself, there is no data governance thing you need to worry about.</p>\n<p>In Metabase, a dashboard is composed of multiple questions. A question is just a single data visualisation view based on a certain SQL query. To create a question, I always prefer to write my own queries as a data scientist myself, just to have the full flexibility, but it is also possible that you do it in a beginner-friendly way. Metabase can understand data structures quite well. You can choose to ask data questions without writing any SQL but just clicking some options Metabase prepared for you.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/0e1sArYqzk-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/0e1sArYqzk-600.webp 600w\"><img alt=\"Create a random table.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/0e1sArYqzk-600.png\" width=\"600\" height=\"257\"></picture></p>\n<p>After processing the data, either through SQL or clicking options on the user interface, you can start visualising the processed data for this question. Based on the structure of processed data, Metabase will offer you all the possible types of visualisations. Choose one and the data will be immediately displayed.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/pk0TG8lqKz-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/pk0TG8lqKz-600.webp 600w\"><img alt=\"Create a random table.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/pk0TG8lqKz-600.png\" width=\"600\" height=\"310\"></picture></p>\n<p>Once you've created all the questions and get them answered by the visuals, you can bring them together into one dashboard. Here is an example of my dashboards. I ingested all my Fanfou (Chinese Twitter especially for Chinese hipsters) posts and stored them in my database. I used a language embedding model to turn every post into an embedding vector. Then I reduced the dimensions to 2 by running a PCA (principal component analysis) algorithm to the embedding vectors.</p>\n<p>In the first question view, I plot the data points of my Fanfou posts in the two dimensions and use colors to indicate the year of the post. In the second question view, I plot the time series of two dimensions of PC (principal components). Apparently, my 2nd-dimension PC has decreased a lot in recent years. I'm not very sure about the virtue of the story yet regarding this mysterious PC2, but it's a lot of fun to have my own text data to be analyzed and visualized.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/yM3n92ysrn-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/yM3n92ysrn-600.webp 600w\"><img alt=\"Create a random table.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/yM3n92ysrn-600.png\" width=\"600\" height=\"383\"></picture></p>\n",
			"date_published": "2024-02-24T00:00:00Z"
		}
		,
		{
			"id": "https://bellowswang.github.io/blog/database/",
			"url": "https://bellowswang.github.io/blog/database/",
			"title": "Everyone (including Snoop Dogg) should have their own databases.",
			"content_html": "<p>To start building our personal DNA (Data and AI) department, we must first own the data. Nowadays, data are usually not owned by ourselves as the users, but by the tech giants as the service providers. It's the time to take our data back. The very first step is to create a self-hosted database.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/SO7y5MHhv4-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/SO7y5MHhv4-600.webp 600w\"><img alt=\"Create a random table.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/SO7y5MHhv4-600.jpeg\" width=\"600\" height=\"600\"></picture></p>\n<h3 id=\"what-is-a-database-wiki-definition\" tabindex=\"-1\">What is a database? (wiki definition) <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/database/\">#</a></h3>\n<blockquote>\n<p>&quot;A database is an organised collection of data (also known as a data store) stored and accessed electronically through the use of a database management system. Small databases can be stored on a file system, while large databases are hosted on computer clusters of cloud storage.&quot;</p>\n</blockquote>\n<h3 id=\"why-a-database-database-vs-gsheet-excel\" tabindex=\"-1\">Why a database? (database vs. gsheet/excel) <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/database/\">#</a></h3>\n<p>Many people without technical background are comfortable with using excel or gsheet. They have two drawbacks:</p>\n<ul>\n<li>The user interface is friendly but it also at the same time limits the performance when the data becomes huge. Imagine loading 10 million rows of data into your excel or gsheet.</li>\n<li>They have their own ecosystems, which means the I/O interface is closed in their ecosystem as well. For example, if you want to visualise the data from a database, since the interface is universal and open, you can visualise them with many different tools. On the other hand, if you want to visualise the data in an excel file or in a gsheet, your options are quite limited.</li>\n</ul>\n<h3 id=\"why-a-database-database-vs-python-pandas\" tabindex=\"-1\">Why a database? (database vs. Python Pandas) <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/database/\">#</a></h3>\n<p>Python is popular nowadays. People might ask why they need to use a database while they can use for example Pandas in Python to process the data.</p>\n<p>Databases are designed for persistent data storage and they are able to handle large volumes of data efficiently, even when the data exceeds the available memory. Data stored in a database remains there even if your Python program or computer crashes.</p>\n<p>Pandas in Python, on the other hand, is primarily an in-memory data manipulation library. Data loaded into pandas DataFrames is stored in memory, and it's lost when your program exits. It's not suitable for long-term data storage or sharing data across multiple applications or users.</p>\n<h3 id=\"types-of-database\" tabindex=\"-1\">Types of database <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/database/\">#</a></h3>\n<p>The most common types include relational databases and NoSQL databases. The former store data in tables with rows and columns. They use a schema to define the structure of the data. The example include PostgreSQL, MySQL, etc. NoSQL databases are designed for flexibility and scalability and can handle unstructured or semi-structured data. The most well-known example is MongoDB, which stores data in the JSON format.</p>\n<h3 id=\"how-to-host-a-database-by-yourself\" tabindex=\"-1\">How to host a database by yourself? <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/database/\">#</a></h3>\n<p>Hosting a database by yourself is way easier than you could imagine. There are just a couple of steps. Let's go through an example where we host PostgreSQL on our local laptop.</p>\n<p>Prepare two files. Name one file as <code class=\"language-\">docker-compose.yml</code> and add the following content.</p>\n<pre class=\"language-yaml\" tabindex=\"0\"><code class=\"language-yaml\"><span class=\"token key atrule\">version</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'3.9'</span>\n<span class=\"token key atrule\">services</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">db</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> postgres\n    <span class=\"token key atrule\">env_file</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> database.env\n    <span class=\"token key atrule\">volumes</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> database<span class=\"token punctuation\">-</span>data<span class=\"token punctuation\">:</span>/var/lib/postgresql/data\n    <span class=\"token key atrule\">ports</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> 5439<span class=\"token punctuation\">:</span><span class=\"token number\">5439</span>\n    <span class=\"token key atrule\">restart</span><span class=\"token punctuation\">:</span> unless<span class=\"token punctuation\">-</span>stopped</code></pre>\n<p>Name the other file as <code class=\"language-\">database.env</code> and add the following content.</p>\n<pre class=\"language-js\" tabindex=\"0\"><code class=\"language-js\"><span class=\"token constant\">POSTGRES_USER</span><span class=\"token operator\">=</span>snoopdogg\n<span class=\"token constant\">POSTGRES_PASSWORD</span><span class=\"token operator\">=</span>dropitlikeitshot\n<span class=\"token constant\">POSTGRES_DB</span><span class=\"token operator\">=</span>doggystyle</code></pre>\n<p>Store these two files in the same path and then run the following command line at that path. Make sure <a href=\"https://www.docker.com/\">docker</a> (including <a href=\"https://docs.docker.com/compose/\">docker-compose</a>) has been installed on your system before running it.</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token function\">docker-compose</span> up</code></pre>\n<p>Let's assume you set up everything on your local laptop. Then you should be able to access to your database through <code class=\"language-\">localhost:5439</code>, using the username, password and database name specified in the <code class=\"language-\">database.env</code> file.</p>\n<h3 id=\"how-to-query-from-a-database\" tabindex=\"-1\">How to query from a database? <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/database/\">#</a></h3>\n<p>Unfortunately, if you enter <code class=\"language-\">localhost:5439</code> as a URL into your browser, you won't be able to access anything. A common interface is a database client (or IDE), which is the graphical user interface where you can connect the database and query the data. One of the most famous cross-platform database clients is <a href=\"https://www.jetbrains.com/datagrip/\">DataGrip</a>, which supports almost all kinds of databases. However, it's not free. I use <a href=\"https://dbeaver.io/\">DBeaver</a> (the Community version) for my personal projects. It's also cross-platform and quite powerful.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/htRLy9Vx8C-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/htRLy9Vx8C-600.webp 600w\"><img alt=\"Set up the database connection in DBeaver.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/htRLy9Vx8C-600.png\" width=\"600\" height=\"470\"></picture></p>\n<p>After setting up the database connection in DBeaver, you can just freely create any table as you want in the database by writing SQL. For example, let's just create a table called <code class=\"language-\">snoop_dogg_playlist</code> in the <code class=\"language-\">staging</code> schema.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/vfhYvGpuJ2-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/vfhYvGpuJ2-600.webp 600w\"><img alt=\"Create a random table.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/vfhYvGpuJ2-600.png\" width=\"600\" height=\"413\"></picture></p>\n<p>Fianlly, you can write another SQL to query from this table you just created.</p>\n<p><picture><source type=\"image/avif\" srcset=\"https://bellowswang.github.io/img/3SMAiR6vNm-600.avif 600w\"><source type=\"image/webp\" srcset=\"https://bellowswang.github.io/img/3SMAiR6vNm-600.webp 600w\"><img alt=\"Create a random table.\" loading=\"lazy\" decoding=\"async\" style=\"max-width: 100%; height: auto;\" src=\"https://bellowswang.github.io/img/3SMAiR6vNm-600.png\" width=\"600\" height=\"234\"></picture></p>\n<h3 id=\"how-to-ingest-data-into-your-database\" tabindex=\"-1\">How to ingest data into your database? <a class=\"header-anchor\" href=\"https://bellowswang.github.io/blog/database/\">#</a></h3>\n<p>It's almost impossible to create all your data by manually writing SQL like <code class=\"language-\">CREATE TABLE XXX AS SELECT ...</code> every single time in DBeaver, not to mention you have to do it row by row for each table. I usually don't do the data ingestion part in this way.</p>\n<p>Remember one advantage of database is the universality of its interface. You can easily connect to a database in Python or R, with certain libraries. Even though we have mentioned Python Pandas might not be the best for long-term data storage, but it can do a great job manipulating the data from external sources and then writing them into a connected database, using the <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html\">to_sql</a> api.</p>\n<p>Just imagine you can run a Python script scraping for example your health data from your smart watch on a regular basis and the data will be regularly inserted into the database, so that you finally own such data in your own database.</p>\n",
			"date_published": "2023-08-28T00:00:00Z"
		}
		
	]
}
